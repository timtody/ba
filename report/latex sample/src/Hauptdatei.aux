\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{alphadin}
\@input{latex_einstellungen/deckblatt.aux}
\@input{abstract.aux}
\@writefile{toc}{\contentsline {section}{Abbildungsverzeichnis}{5}{section*.4}}
\@writefile{toc}{\contentsline {section}{Tabellenverzeichnis}{6}{section*.5}}
\@writefile{toc}{\contentsline {section}{Listingverzeichnis}{6}{section*.6}}
\@writefile{toc}{\contentsline {section}{Abkürzungsverzeichnis}{6}{section*.7}}
\citation{DICARLO2012415}
\citation{NIPS2012_4824}
\citation{Sugase1999}
\@writefile{toc}{\contentsline {section}{\numberline {1}Einleitung}{7}{section.1}}
\newlabel{Einleitung}{{1}{7}{Einleitung}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Grundlagen}{7}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Überwachtes Lernen}{7}{subsection.2.1}}
\citation{hastie01statisticallearning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Lineare Modelle}{8}{subsubsection.2.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Biologischer Hintergrund}{8}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Neuronen}{9}{subsection.2.3}}
\newlabel{sec:neurons}{{2.3}{9}{Neuronen}{subsection.2.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Schematische Darstellung eines Neurons}}{9}{figure.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Spannungsänderung während eines Aktionspotentials}}{9}{figure.2}}
\citation{rosenblatt1958perceptron}
\citation{mcculloch1943logical}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Abbildung einer Synapse}}{10}{figure.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Neuronale Netze}{10}{subsection.2.4}}
\citation{lecun1998gradient}
\citation{krizhevsky2012imagenet}
\citation{matsugu2003subject}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Ein einfaches Perzeptron mit n Eingängen}}{11}{figure.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Convolutional Neural Networks}{11}{subsection.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Ein CNN klassifiziert mehrere Objekte pro Bild korrekt mit hoher Konfidenz}}{12}{figure.5}}
\newlabel{https://arxiv.org/pdf/1506.01497v3.pdf}{{5}{12}{Ein CNN klassifiziert mehrere Objekte pro Bild korrekt mit hoher Konfidenz}{figure.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.1}Architektur}{12}{subsubsection.2.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Beispielhafte Architektur eines CNNs. Subsampling steht hierbei für Pooling-Layer.}}{13}{figure.6}}
\newlabel{fig1}{{6}{13}{Beispielhafte Architektur eines CNNs. Subsampling steht hierbei für Pooling-Layer}{figure.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.2}FaltungsLayer}{14}{subsubsection.2.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Verschiedene Faltungskernel}}{14}{figure.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.5.3}Pooling-Layer}{14}{subsubsection.2.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Rekurrente Neuronale Netze}{14}{subsection.2.6}}
\citation{rumelhart1988learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Approximation von Rekursion}{15}{subsection.2.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Ein RNN wird über n Zeitschritte entfaltet. Die Netzwerkeingaben $x_1,..., x_n$ müssen hierbei alle zur Verfügung stehen.}}{15}{figure.8}}
\newlabel{img:rnn}{{8}{15}{Ein RNN wird über n Zeitschritte entfaltet. Die Netzwerkeingaben $x_1,..., x_n$ müssen hierbei alle zur Verfügung stehen}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Backpropagation}{15}{subsection.2.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9}Backpropagation Through Time}{16}{subsection.2.9}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Materials and Methods}{16}{section.3}}
\newlabel{Materialien und Methoden}{{3}{16}{Materials and Methods}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Generatives Modell für Stimuli}{16}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Models}{16}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Implementation}{17}{subsubsection.3.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Recurrent Convolution Layers}{17}{subsubsection.3.2.2}}
\citation{NIPS2012_4824}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training}{18}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Error Measurement}{18}{subsubsection.3.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Backpropagation Through Time}{18}{subsubsection.3.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Truncated Backpropagation Through Time}{19}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Ergebnisse}{19}{section.4}}
\newlabel{Ergebnisse}{{4}{19}{Ergebnisse}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Performance changes under varying levels of occlusion}{20}{subsection.4.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Diskussion}{20}{section.5}}
\newlabel{Diskussion}{{5}{20}{Diskussion}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Danksagung}{20}{section.6}}
\newlabel{Danksagung}{{6}{20}{Danksagung}{section.6}{}}
\bibdata{Hauptdatei}
\bibcite{DICARLO2012415}{DZR12}
\bibcite{hastie01statisticallearning}{HTF01}
\bibcite{hubel1962receptive}{HW62}
\bibcite{NIPS2012_4824}{KSH12a}
\bibcite{krizhevsky2012imagenet}{KSH12b}
\bibcite{lecun1998gradient}{LBBH98}
\bibcite{matsugu2003subject}{MMMK03}
\bibcite{mcculloch1943logical}{MP43}
\bibcite{rumelhart1988learning}{RHW{$^{+}$}88}
\bibcite{rosenblatt1958perceptron}{Ros58}
\bibcite{Sugase1999}{SYUK99}
\@writefile{toc}{\contentsline {section}{Literaturverzeichnis}{21}{section.6}}
\@writefile{toc}{\contentsline {section}{Anhang}{22}{section*.8}}
\newlabel{anhang}{{6}{22}{Anhang}{section*.9}{}}
\@writefile{toc}{\contentsline {section}{Eidesstattliche Erklärung}{22}{section*.9}}
\@input{erklaerung.aux}
